<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>NAACL 2022 | Aryaman Arora</title>
<meta name=keywords content="NLP"><meta name=description content="NAACL was the best conference experience I've ever had, no doubt about it."><meta name=author content="Me"><link rel=canonical href=http://localhost:1313/posts/2022-08-04-naacl/><link crossorigin=anonymous href=/assets/css/stylesheet.2c337fb86f9536060b454f4a8b7f1d6740cceb72dc167ed453d119184019fa6a.css integrity="sha256-LDN/uG+VNgYLRU9Ki38dZ0DM63LcFn7UU9EZGEAZ+mo=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/icon.png><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/icon.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/icon.png><link rel=apple-touch-icon href=http://localhost:1313/icon.png><link rel=mask-icon href=http://localhost:1313/icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/2022-08-04-naacl/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-W6HV8VE5SV"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-W6HV8VE5SV",{anonymize_ip:!1})}</script><meta property="og:title" content="NAACL 2022"><meta property="og:description" content="NAACL was the best conference experience I've ever had, no doubt about it."><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/posts/2022-08-04-naacl/"><meta property="og:image" content="http://localhost:1313/icon.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-08-04T00:00:00+00:00"><meta property="article:modified_time" content="2022-08-04T00:00:00+00:00"><meta property="og:site_name" content="Aryaman Arora"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/icon.png"><meta name=twitter:title content="NAACL 2022"><meta name=twitter:description content="NAACL was the best conference experience I've ever had, no doubt about it."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"NAACL 2022","item":"http://localhost:1313/posts/2022-08-04-naacl/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"NAACL 2022","name":"NAACL 2022","description":"NAACL was the best conference experience I've ever had, no doubt about it.","keywords":["NLP"],"articleBody":"I entered the NAACL conference venue, just a couple blocks away from my place in Seattle, with the absolute lowest of expectations. I have attended two other conferences this year entirely online: ACL and LREC. At both, I had minimal interactions with other human beings beyond “standing” at my poster, and most of that time no one was even there to ask about my work. Hence, zero expectations.\nThe Multimodal ML tutorial.\nNAACL was the best conference experience I’ve ever had, no doubt about it. The posters and talks were fascinating, I learned a lot from the tutorials, the socials were both fun and a great way to meet people, and there was great food. I can easily say that I met more people at NAACL than I did in all my previous conferences combined. More than the paper talks or presentations, the value of a conference is in being able to easily meet new people who offer a diversity of perspectives. It was also great to experience how approachable even the biggest names in NLP are.\nA big theme of the conference seemed to be the uncertain role of symbolic systems, often inspired by linguistics, in an overwhelmingly neural field. There was a somewhat terse back-and-forth at the panel between Emily Bender and Chris Manning which struck at some of the fundamental points of debate in the field: what are we trying to do as computational linguists by training big language models, and could those things be done in a different way? We’ve seen a big convergence in AI in the past couple years on the topic of model architecture; every field has benefited from training transformer models on massive amounts of unlabelled data and finetuning them on (or prompting them about) data-limited and specific tasks. But maybe this convergence comes at the cost of dismissing alternatives. (I’m not sure I explained that very clearly.)\nProbably the most important thing I took away is that NLP is much bigger than computational linguistics. I consider myself a linguist; I find language absolutely fascinating and its existence and development pretty much insane. Understanding how the complex and intricate system that makes up language works is satisfying. But, linguistics is a very confused field—the more I learn about, the less I can get what it’s trying to say or whether its story of language is coherent. It’s hard to say what its place is at the cutting edge of NLP, where unsupervised systems reign supreme now. Seeing the wealth of development in e.g. multimodal ML, which was barely a thing two years ago in my view, has convinced me that looking beyond linguistics is exciting too.\nAnyway, I don’t think my narrative of this conference is going to form a coherent whole either, so I’ll just note down random experiences that I remember from the conference.\nEating pho with Justus Mattern (differential privacy), one of the limited number of undergrads at NAACL, before the conference. Us and Rohan Pandey (semantic parsing/linguistics in NLP) ended up attending much of the conference and socials together. Gasworks. One of my favourite views of Seattle.\nWalking aimlessly around Seattle with Machel Reid (low-resource MT, LM things), also before the conference. Talking to Dzmitry Bahdanau (first author on the paper that introduced attention; a real fanboy moment) at the MoPOP social. I am proud of maintaining surprisingly high-level conversation which I learned a lot from—one thing I’ll keep thinking about is his mention of the “high-risk, high-reward” challenge of beating transformers. The Museum of Pop Culture.\nTalking to Venelin Kovatchev about Bulgarian for half an hour, and randomly more throughout the conference. Having lunch at a Sichuanese restaurant with Eleanor Jiang and some others. This was funny to me because I ended up meeting more ETH-affliated people at NAACL than I did while actually at ETH, due to the work-from-home policy last summer there. Learning about embeddings in hyperbolic spaces from Jun Takeuchi’s excellent poster at the SRW. This is an idea I had could have never even known to look for, and the presentation was very well done. Meeting Matyáš Boháček, a 10th-grader (!!) who does research in NLP and ML broadly. As someone who got into research early too but not that early, this kind of thing is very humbling. Talking to Paul Smolensky (the inventor of optimality theory; again a fanboy moment) about the panel and randomly chatting like normal people throughout the conference. Talking to Shaily Bhatt during the workshops. In general, it’s cool to see the exciting new work and opportunities going on in India, especially on NLP for Indian langauges. Also was really great to finally meet Monojit Choudhury in-person at the social. Seeing Ruibo Liu’s paper on AI alignment. I have thoughts™ on alignment as a research programme, but anyway this made me think a lot about how we evaluate generative language models on free-text generation. Visiting the AI2 social (which we somehow got into despite not being able to RSVP) and joining random circles of people and talking about everything. I really enjoyed talking to Ashish Sabharwal and Zhijing Jin. AI2 also had a great selection of cheeses. Playing some game whose name I do not know (it was a bit like curling on a table?) at the DADC rooftop social, with great views of Seattle. I talked to Martijn Bartelds (Dutch dialectology) and a bunch of UCSC people. A view of Seattle from the DADC rooftop.\nThe talk for “Do Prompt-Based Models Really Understand the Meaning of their Prompts?” by Albert Webson and Ellie Pavlick. I had seen an earlier version of this at MASC-SLL. This affirms, to a degree, the intuitive suspicions that arise about the effectiveness of prompting. But of course, we have work pointing the other way too now, with chain-of-thought prompting. In general, the conference left me with a lot of new ideas and uncertainties. I was definitely affirmed about my choice of sticking towards research. It was exciting to see all the new things happening at NAACL! There is a unique wonder of being at the cutting edge of a rapidly-maturing field. There is a dizzing array of directions to work towards, in uncharted territory, even for the least experienced researchers. At the same time, the results of new work are immediately apparent due to the inherent scalability of software. To me, this is the best of both worlds.\nOn the other hand, I am increasingly disappointed in the place of linguistics in this new work. Language is a beautiful and complex system, grounded in social interaction, but it does not feel like the direction that NLP is going in really is benefitting from the work of linguists. I think my disillusionment is not with NLP though. NLP is successful. Computational linguistics is successfully using the engineering breakthroughs of NLP to better understand language. But the way in which this is progressing is totally divorced from the field of linguistics, which makes linguistics feel like a bit of a dead end.\nAnyway, NAACL was great, and these are exciting times in the field.\n","wordCount":"1180","inLanguage":"en","image":"http://localhost:1313/icon.png","datePublished":"2022-08-04T00:00:00Z","dateModified":"2022-08-04T00:00:00Z","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/2022-08-04-naacl/"},"publisher":{"@type":"Organization","name":"Aryaman Arora","logo":{"@type":"ImageObject","url":"http://localhost:1313/icon.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Aryaman Arora (Alt + H)">Aryaman Arora</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/about/ title=about><span>about</span></a></li><li><a href=http://localhost:1313/papers/ title=papers><span>papers</span></a></li><li><a href=http://localhost:1313/posts/ title=blog><span>blog</span></a></li><li><a href=http://localhost:1313/search/ title=search><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">NAACL 2022</h1><div class=post-description>NAACL was the best conference experience I've ever had, no doubt about it.</div><div class=post-meta><span title='2022-08-04 00:00:00 +0000 UTC'>August 4, 2022</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;1180 words&nbsp;·&nbsp;Me</div></header><div class=post-content><p>I entered the NAACL conference venue, just a couple blocks away from my
place in Seattle, with the absolute lowest of expectations. I have
attended two other conferences this year entirely online: ACL and LREC.
At both, I had minimal interactions with other human beings beyond
&ldquo;standing&rdquo; at my poster, and most of that time no one was even there to
ask about my work. Hence, zero expectations.</p><figure class=align-center><img loading=lazy src=/img/multimodal.jpg#center alt="The Multimodal ML tutorial."><figcaption><p>The Multimodal ML tutorial.</p></figcaption></figure><p><strong>NAACL was the best conference experience I&rsquo;ve ever had</strong>, no doubt
about it. The posters and talks were fascinating, I learned a lot from
the tutorials, the socials were both fun and a great way to meet people,
and there was great food. I can easily say that I met more people at
NAACL than I did in all my previous conferences combined. More than the
paper talks or presentations, the value of a conference is in being able
to easily meet new people who offer a diversity of perspectives. It was
also great to experience how approachable even the biggest names in NLP
are.</p><p>A big theme of the conference seemed to be the uncertain role of
symbolic systems, often inspired by linguistics, in an overwhelmingly
neural field. There was a somewhat terse back-and-forth at the panel
between Emily Bender and Chris Manning which struck at some of the
fundamental points of debate in the field: what are we trying to do as
computational linguists by training big language models, and could those
things be done in a different way? We&rsquo;ve seen a big convergence in AI in
the past couple years on the topic of model architecture; every field
has benefited from training transformer models on massive amounts of
unlabelled data and finetuning them on (<a href=https://arxiv.org/abs/2205.11916>or prompting them
about</a>) data-limited and specific
tasks. But maybe this convergence comes at the cost of dismissing
alternatives. (I&rsquo;m not sure I explained that very clearly.)</p><p>Probably the most important thing I took away is that NLP is much bigger
than computational linguistics. I consider myself a linguist; I find
language absolutely fascinating and its existence and development pretty
much insane. Understanding how the complex and intricate system that
makes up language works is satisfying. But, linguistics is a very
confused field—the more I learn about, the less I can get what it&rsquo;s
trying to say or whether its story of language is coherent. It&rsquo;s hard to
say what its place is at the cutting edge of NLP, where unsupervised
systems reign supreme now. Seeing the wealth of development in e.g.
multimodal ML, which was barely a thing two years ago in my view, has
convinced me that looking beyond linguistics is exciting too.</p><p>Anyway, I don&rsquo;t think my narrative of this conference is going to form a
coherent whole either, so I&rsquo;ll just note down random experiences that I
remember from the conference.</p><ul><li>Eating pho with <a href=https://justusmattern.github.io>Justus Mattern</a>
(differential privacy), one of the limited number of undergrads at
NAACL, before the conference. Us and <a href=https://rpandey.tech>Rohan
Pandey</a> (semantic parsing/linguistics in NLP)
ended up attending much of the conference and socials together.<figure class=align-center><img loading=lazy src=/img/gasworks.jpg#center alt="Gasworks. One of my favourite views of Seattle."><figcaption><p>Gasworks. One of my favourite views of Seattle.</p></figcaption></figure></li><li>Walking aimlessly around Seattle with <a href=https://machelreid.github.io>Machel
Reid</a> (low-resource MT, LM things),
also before the conference.</li><li>Talking to <a href=http://rizar.github.io>Dzmitry Bahdanau</a> (first author
on the paper that introduced attention; a real fanboy moment) at the
MoPOP social. I am proud of maintaining surprisingly high-level
conversation which I learned a lot from—one thing I&rsquo;ll keep thinking
about is his mention of the &ldquo;high-risk, high-reward&rdquo; challenge of
beating transformers.<figure class=align-center><img loading=lazy src=/img/mopo.jpg#center alt="The Museum of Pop Culture."><figcaption><p>The Museum of Pop Culture.</p></figcaption></figure></li><li>Talking to <a href=http://vkovatchev.com>Venelin Kovatchev</a> about
Bulgarian for half an hour, and randomly more throughout the
conference.</li><li>Having lunch at a Sichuanese restaurant with <a href=https://www.elejiang.me>Eleanor
Jiang</a> and some others. This was funny to
me because I ended up meeting more ETH-affliated people at NAACL
than I did while actually at ETH, due to the work-from-home policy
last summer there.</li><li>Learning about embeddings in hyperbolic spaces from <a href=https://aclanthology.org/2022.naacl-srw.27/>Jun Takeuchi&rsquo;s
excellent poster</a> at
the SRW. This is an idea I had could have never even known to look
for, and the presentation was very well done.</li><li>Meeting Matyáš Boháček, a 10th-grader (!!) who does research in NLP
and ML broadly. As someone who got into research early too but not
that early, this kind of thing is very humbling.</li><li>Talking to <a href=https://en.wikipedia.org/wiki/Paul_Smolensky>Paul
Smolensky</a> (the
inventor of optimality theory; again a fanboy moment) about the
panel and randomly chatting like normal people throughout the
conference.</li><li>Talking to <a href=https://sites.google.com/view/shailybhatt/>Shaily
Bhatt</a> during the
workshops. In general, it&rsquo;s cool to see the exciting new work and
opportunities going on in India, especially on NLP for Indian
langauges. Also was really great to finally meet <a href=https://www.microsoft.com/en-us/research/people/monojitc/>Monojit
Choudhury</a>
in-person at the social.</li><li>Seeing <a href=https://aclanthology.org/2022.findings-naacl.18/>Ruibo Liu&rsquo;s paper on AI
alignment</a>. I have
thoughts™ on alignment as a research programme, but anyway this made
me think a lot about how we evaluate generative language models on
free-text generation.</li><li>Visiting the AI2 social (which we somehow got into despite not being
able to RSVP) and joining random circles of people and talking about
everything. I really enjoyed talking to <a href=https://allenai.org/team/ashishs>Ashish
Sabharwal</a> and <a href=https://zhijing-jin.com/fantasy>Zhijing
Jin</a>. AI2 also had a great
selection of cheeses.</li><li>Playing some game whose name I do not know (it was a bit like
curling on a table?) at the DADC rooftop social, with great views of
Seattle. I talked to <a href=https://martijnbartelds.nl>Martijn Bartelds</a>
(Dutch dialectology) and a bunch of UCSC people.<figure class=align-center><img loading=lazy src=/img/seattle.jpg#center alt="A view of Seattle from the DADC rooftop."><figcaption><p>A view of Seattle from the DADC rooftop.</p></figcaption></figure></li><li>The talk for &ldquo;<a href=https://arxiv.org/abs/2109.01247>Do Prompt-Based Models Really Understand the Meaning
of their Prompts?</a>&rdquo; by Albert
Webson and Ellie Pavlick. I had seen an earlier version of this at
MASC-SLL. This affirms, to a degree, the intuitive suspicions that
arise about the effectiveness of prompting. But of course, we have
work pointing the other way too now, with chain-of-thought
prompting.</li></ul><p>In general, the conference left me with a lot of new ideas and
uncertainties. I was definitely affirmed about my choice of sticking
towards research. It was exciting to see all the new things happening at
NAACL! There is a unique wonder of being at the cutting edge of a
rapidly-maturing field. There is a dizzing array of directions to work
towards, in uncharted territory, even for the least experienced
researchers. At the same time, the results of new work are immediately
apparent due to the inherent scalability of software. To me, this is the
best of both worlds.</p><p>On the other hand, I am increasingly disappointed in the place of
linguistics in this new work. Language is a beautiful and complex
system, grounded in social interaction, but it does not feel like the
direction that NLP is going in really is benefitting from the work of
linguists. I think my disillusionment is not with NLP though. NLP is
successful. Computational linguistics is successfully using the
engineering breakthroughs of NLP to better understand language. But the
way in which this is progressing is totally divorced from the field of
linguistics, which makes linguistics feel like a bit of a dead end.</p><p>Anyway, NAACL was great, and these are exciting times in the field.</p></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/nlp/>NLP</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/posts/2022-10-08-ccg/><span class=title>« Prev</span><br><span>Some CCG derivations in Hindi</span>
</a><a class=next href=http://localhost:1313/posts/2022-06-21-kitaev/><span class=title>Next »</span><br><span>A machine-learned syntactic tagset?</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Aryaman Arora</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>