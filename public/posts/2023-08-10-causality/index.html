<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>The Hittite problem | Aryaman Arora</title>
<meta name=keywords content="NLP,causality"><meta name=description content="How do we interpret neural networks? We should start by comparing it to the geopolitical situation of early Indo-European Anatolia."><meta name=author content="Me"><link rel=canonical href=http://localhost:1313/posts/2023-08-10-causality/><link crossorigin=anonymous href=/assets/css/stylesheet.2c337fb86f9536060b454f4a8b7f1d6740cceb72dc167ed453d119184019fa6a.css integrity="sha256-LDN/uG+VNgYLRU9Ki38dZ0DM63LcFn7UU9EZGEAZ+mo=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/2023-08-10-causality/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-W6HV8VE5SV"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-W6HV8VE5SV",{anonymize_ip:!1})}</script><meta property="og:title" content="The Hittite problem"><meta property="og:description" content="How do we interpret neural networks? We should start by comparing it to the geopolitical situation of early Indo-European Anatolia."><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/posts/2023-08-10-causality/"><meta property="og:image" content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-08-10T00:00:00+00:00"><meta property="article:modified_time" content="2023-08-10T00:00:00+00:00"><meta property="og:site_name" content="Aryaman Arora"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="The Hittite problem"><meta name=twitter:description content="How do we interpret neural networks? We should start by comparing it to the geopolitical situation of early Indo-European Anatolia."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"The Hittite problem","item":"http://localhost:1313/posts/2023-08-10-causality/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"The Hittite problem","name":"The Hittite problem","description":"How do we interpret neural networks? We should start by comparing it to the geopolitical situation of early Indo-European Anatolia.","keywords":["NLP","causality"],"articleBody":"You are a Hittite spy. You report directly to the great king Šuppiluliuma I, who rules from his magnificent capital at Ḫattuša. Recently, the Hittites have been on good terms with their neighbours the Hurrians. Still, you can never be too sure about even the best of allies, and therefore the king has sent you to infilitrate the Hurrian bureauracy so that you can pre-empt any conspiracies brewing within.1\nYou are so good at your job that you have totally compromised all incoming information channels into the Hurrian government apparatus—you can mess with their weather reports, their intelligence dossiers, their tax records, etc. However, there is one big problem preventing you from completely compromising this adversary: all of their internal communication is encrypted and your cryptographers have made no progress at cracking the code. Furthermore, no one inside the government can be bribed to reveal how the encryption works, since the encryption method is so complex that no single person (let alone a random civil servant) can understand how it works.2 Basically, you can only mess with what’s coming in (all information channels, including internal ones) and observe what goes out (governmental decisions decided by the top brass).\nKnowing who is in charge of what will be useful for identifying high-value targets or figuring out what minimal set of information channels to manipulate to steer the government into doing what you want. So how can you figure out how the government is structured?\nThis is the interpretability problem.\nHere are some of the approaches the surprisingly sophisticated Hittite geopolitics experts have suggested over the years for cracking this problem:\nProbing: Access past internal encrypted communications and resulting government decisions and train machine learning models to try and guess what the government will do based on just the communications. You’re just a spy though—you don’t understand machine learning and you don’t see how this tells you anything useful about who’s in charge of what. (Breaking out of character: this doesn’t establish causality between decisions and communications—you only know X information could be used based on this activation, not whether the model actually does so. And interpreting a model with another model is… an interesting choice. I feel like we can do better.)3 Interpret attention patterns: While you can’t tell what the content of each encrypted message is, you do know who is sending it to who and what information channels are being accessed. So you can establish who is whose superior, and what input information some decisions may be based on. But you are missing the actual meaningful part of the messages: their content! (Attention patterns are seductively easy to visualise, but again they don’t establish causality between parts of a model. The attention pattern doesn’t tell us how information is used or manipulated, only where it goes.)4 Zero ablation: Erase some set of internal messages and see what happens. This might not tell you much though since it may just cause confusion in the governmental ranks, probably making some superiors angry at their subordinates for not transmitting important information rather than meaningfully affecting governmental decisions. (Zero ablation may throw the model off-distribution in an important way, since you have no idea what a zero vector as an internal activation actually means—e.g. maybe “no information” is encoded as a non-zero vector.)5 Mean ablation: Take all encrypted communications recorded over a particular channel in the past. In this analogy we can’t really take the mean over activations, but let’s say we produce a really boring and average communication (e.g. the mode). This means no important (i.e. anomalous, low-surprisal) information gets transferred over this channel. So e.g. you may be able to figure out who in the government handles disaster response if you replace their “oh no!” message into an everyday “all clear” message. (This might again be weirdly off distribution. In a real model, you might then be taking the mean of a non-normally distributed activation and producing some weird new stuff the model has never seen before.) Path patching or interchange intervention: Feed wrong information to only some people in the government or only along some chains of command. See how the response changes—you can causally establish what people are responsible for delivering certain kinds of information up the chain of command.6 Resampling ablation: Pick a random encrypted message from the past. Substitute it in place of the one being transmitted today. Do this a bunch of times with different random messages and see what happens—e.g. maybe suddenly the government is unable to feed its population, in which case you know you messed with someone responsible for agriculture. (Easier to automate than the above but hard to figure out how to set up your experiments.)7 Okay now I’ll break out of character.\nWhat is the best method for figuring out how a neural network computes something? It’s barely been a couple years and so many different approaches have proliferated. I haven’t even listed all the possible approaches because some of them are pretty hard to analogise—e.g., iterative nullspace projections attempt to remove concepts in the activation space by (iteratively) projecting activations onto the nullspace of linear probes trained to predict that concept (see Ravfogel et al., 2020). There’s a bunch of work on fact-editing in transformers too that is relevant to interpretability as well. I also don’t even mention explainability methods (which sometimes aren’t conceptually different from probing).\nBroadly, I think methods that establish causality are the most promising and well-founded. The argument for causality stems from the deficiency in probing that I think is best articulated in Geiger et al. (2023):\nFrom an information-theoretic point of view, we can observe that using arbitrarily powerful probes is equivalent to measuring the mutual information between the concept and the neural representation (Hewitt and Liang, 2019; Pimentel et al., 2020). If we restrict the class of probing models based on their complexity, we can measure how usable the information is (Xu et al., 2020; Hewitt et al., 2021). Regardless of what probe models are used, successfully probing a neural representation does not guarantee that the representation plays a causal role in model behavior (Ravichander et al., 2020; Elazar et al., 2020; Geiger et al., 2020, 2021).\nWhat we want to know, when interpreting how a model works, is how information is used to produce the output. What probing tells is whether that information could be used to produce a desired output. To illustrate the point above about probes measuring mutual information: imagine your transformer model internally one-hot encodes your vocabulary. You want to probe whether the model knows if a word is a noun or not. With an MLP probe on the embeddings (with sufficient layers), you would think yes—because an NN with nonlinearities can approximate any function, and any function on your vocabulary can be encoded on one-hot vector inputs! Your probe would basically just have to learn a lookup table, never mind whether or how the model does. This is formalised in the data processing inequality and first pointed out in NLP literature by Pimentel et al. (2020).\nWe don’t actually care about whether information could be extracted from a representation. We care about whether it is by the model we’re studying. Causal abstraction methods, which test counterfactual inputs to parts of the model that let uss modify specific information, can tell us this.\nI think NLP should employ more whacky analogies (see e.g. Leslie Lamport’s work on distributed systems). I am sorry in advance if this makes no sense! ↩︎\nI know it’s not a perfect analogy so you can poke holes in it if you like. Or just assume every government worker is completely loyal so you can’t just manipulate people to get what you want. ↩︎\nI am a real scholar so I will try to cite some papers. But there’s way too much probing literature to sift through. Start with ctrl-F “probing” on Rogers et al. (2021). ↩︎\nClark et al. (2019) ↩︎\nFrom here on out, we are in the Wild West of mechanistic interpretability, where much interesting work is very recent and confined to blogposts that can be kind of hard to understand, rather than arXiv papers (which tbh are often still hard to understand). The earliest use of zero ablation is probably nostalgebraist (2020), who zero-ablated internal model layers to get a sort of early peak into what activations may mean in terms of the vocabulary. You see the method often used by LessWrong-ers. Also, note that zero ablation should be pretty useless on models trained with dropout (since that applies zero ablation to increase model robustness), as pointed out by Neel Nanda. ↩︎\nPath patching comes from Wang et al. (2022) which was the first work to find a circuit accomplishing a specific task in GPT-2 Small. The method is expounded upon in Goldkowsky-Dill et al. (2023) [which I am an author on]. Interchange interventions come from this line of work: Geiger et al. (2023), Geiger et al. (2021). The basic idea between the two lines of work is the same, but I have yet to fully understand the latter series to be confident that the implementation is the same too. ↩︎\nResampling ablations are used in Goldkowsky-Dill et al. (2023). A promising kind of work is automated circuit interpretability as implemented by Conmy et al. (2023). ↩︎\n","wordCount":"1548","inLanguage":"en","image":"http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2023-08-10T00:00:00Z","dateModified":"2023-08-10T00:00:00Z","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/2023-08-10-causality/"},"publisher":{"@type":"Organization","name":"Aryaman Arora","logo":{"@type":"ImageObject","url":"http://localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Aryaman Arora (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Aryaman Arora</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/about/ title=about><span>about</span></a></li><li><a href=http://localhost:1313/papers/ title=papers><span>papers</span></a></li><li><a href=http://localhost:1313/posts/ title=blog><span>blog</span></a></li><li><a href=http://localhost:1313/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">The Hittite problem</h1><div class=post-description>How do we interpret neural networks? We should start by comparing it to the geopolitical situation of early Indo-European Anatolia.</div><div class=post-meta><span title='2023-08-10 00:00:00 +0000 UTC'>August 10, 2023</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;1548 words&nbsp;·&nbsp;Me</div></header><div class=post-content><p><strong>You are a <a href=https://en.wikipedia.org/wiki/Hittites>Hittite</a> spy.</strong> You report directly to the great king <a href=https://en.wikipedia.org/wiki/%C5%A0uppiluliuma_I>Šuppiluliuma I</a>, who rules from his magnificent capital at Ḫattuša. Recently, the Hittites have been on good terms with their neighbours <a href=https://en.wikipedia.org/wiki/Hurrians>the Hurrians</a>. Still, you can never be too sure about even the best of allies, and therefore the king has sent you to infilitrate the Hurrian bureauracy so that you can pre-empt any conspiracies brewing within.<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></p><p>You are so good at your job that you have totally compromised all incoming information channels into the Hurrian government apparatus&mdash;you can mess with their weather reports, their intelligence dossiers, their tax records, etc. However, there is one big problem preventing you from completely compromising this adversary: all of their internal communication is encrypted and your cryptographers have made no progress at cracking the code. Furthermore, no one inside the government can be bribed to reveal how the encryption works, since the encryption method is so complex that no single person (let alone a random civil servant) can understand how it works.<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> Basically, you can only mess with what&rsquo;s <strong>coming in</strong> (all information channels, including internal ones) and observe what <strong>goes out</strong> (governmental decisions decided by the top brass).</p><p>Knowing who is in charge of what will be useful for identifying high-value targets or figuring out what minimal set of information channels to manipulate to steer the government into doing what you want. So how can you figure out how the government is structured?</p><p>This is the interpretability problem.</p><p>Here are some of the approaches the surprisingly sophisticated Hittite geopolitics experts have suggested over the years for cracking this problem:</p><ol><li><strong>Probing</strong>: Access past internal encrypted communications and resulting government decisions and train machine learning models to try and guess what the government will do based on just the communications. You&rsquo;re just a spy though&mdash;you don&rsquo;t understand machine learning and you don&rsquo;t see how this tells you anything useful about who&rsquo;s in charge of what. <em>(Breaking out of character: this doesn&rsquo;t establish causality between decisions and communications&mdash;you only know X information <strong>could</strong> be used based on this activation, not whether the model actually does so. And interpreting a model with another model is&mldr; an interesting choice. I feel like we can do better.)</em><sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup></li><li><strong>Interpret attention patterns</strong>: While you can&rsquo;t tell what the content of each encrypted message is, you do know who is sending it to who and what information channels are being accessed. So you can establish who is whose superior, and what input information some decisions <em>may</em> be based on. But you are missing the actual meaningful part of the messages: their content! <em>(Attention patterns are seductively easy to visualise, but again they don&rsquo;t establish causality between parts of a model. The attention pattern doesn&rsquo;t tell us <strong>how</strong> information is used or manipulated, only where it goes.)</em><sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup></li><li><strong>Zero ablation</strong>: Erase some set of internal messages and see what happens. This might not tell you much though since it may just cause confusion in the governmental ranks, probably making some superiors angry at their subordinates for not transmitting important information rather than meaningfully affecting governmental decisions. <em>(Zero ablation may throw the model off-distribution in an important way, since you have no idea what a zero vector as an internal activation actually means&mdash;e.g. maybe &ldquo;no information&rdquo; is encoded as a non-zero vector.)</em><sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup></li><li><strong>Mean ablation</strong>: Take all encrypted communications recorded over a particular channel in the past. In this analogy we can&rsquo;t really take the mean over activations, but let&rsquo;s say we produce a really boring and average communication (e.g. the mode). This means no important (i.e. anomalous, low-surprisal) information gets transferred over this channel. So e.g. you may be able to figure out who in the government handles disaster response if you replace their &ldquo;oh no!&rdquo; message into an everyday &ldquo;all clear&rdquo; message. <em>(This might again be weirdly off distribution. In a real model, you might then be taking the mean of a non-normally distributed activation and producing some weird new stuff the model has never seen before.)</em></li><li><strong>Path patching</strong> or <strong>interchange intervention</strong>: Feed wrong information to only some people in the government or only along some chains of command. See how the response changes&mdash;you can causally establish what people are responsible for delivering certain kinds of information up the chain of command.<sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup></li><li><strong>Resampling ablation</strong>: Pick a random encrypted message from the past. Substitute it in place of the one being transmitted today. Do this a bunch of times with different random messages and see what happens&mdash;e.g. maybe suddenly the government is unable to feed its population, in which case you know you messed with someone responsible for agriculture. <em>(Easier to automate than the above but hard to figure out how to set up your experiments.)</em><sup id=fnref:7><a href=#fn:7 class=footnote-ref role=doc-noteref>7</a></sup></li></ol><p><em>Okay now I&rsquo;ll break out of character.</em></p><p>What is the best method for figuring out how a neural network computes something? It&rsquo;s barely been a couple years and so many different approaches have proliferated. I haven&rsquo;t even listed all the possible approaches because some of them are pretty hard to analogise&mdash;e.g., <strong>iterative nullspace projections</strong> attempt to remove concepts in the activation space by (iteratively) projecting activations onto the nullspace of linear probes trained to predict that concept (see <a href=https://arxiv.org/pdf/2004.07667.pdf>Ravfogel et al., 2020</a>). There&rsquo;s a bunch of work on fact-editing in transformers too that is relevant to interpretability as well. I also don&rsquo;t even mention explainability methods (which sometimes aren&rsquo;t conceptually different from probing).</p><p>Broadly, I think methods that <strong>establish causality</strong> are the most promising and well-founded. The argument for causality stems from the deficiency in probing that I think is best articulated in <a href=https://arxiv.org/pdf/2301.04709.pdf>Geiger et al. (2023)</a>:</p><blockquote><p>From an information-theoretic point of view, we can
observe that using arbitrarily powerful probes is equivalent to measuring the mutual information
between the concept and the neural representation (Hewitt and Liang, 2019; Pimentel et al., 2020).
If we restrict the class of probing models based on their complexity, we can measure how usable
the information is (Xu et al., 2020; Hewitt et al., 2021). Regardless of what probe models are used,
successfully probing a neural representation does not guarantee that the representation plays a causal
role in model behavior (Ravichander et al., 2020; Elazar et al., 2020; Geiger et al., 2020, 2021).</p></blockquote><p>What we want to know, when interpreting how a model works, is how information <em>is</em> used to produce the output. What probing tells is whether that information <em>could</em> be used to produce a <em>desired</em> output. To illustrate the point above about probes measuring mutual information: imagine your transformer model internally one-hot encodes your vocabulary. You want to probe whether the model knows if a word is a noun or not. With an MLP probe on the embeddings (with sufficient layers), you would think yes&mdash;because an NN with nonlinearities can approximate any function, and any function on your vocabulary can be encoded on one-hot vector inputs! Your probe would basically just have to learn a lookup table, never mind whether or how the model does. This is formalised in the <a href=https://en.wikipedia.org/wiki/Data_processing_inequality>data processing inequality</a> and first pointed out in NLP literature by <a href=https://aclanthology.org/2020.acl-main.420.pdf>Pimentel et al. (2020)</a>.</p><p>We don&rsquo;t actually care about whether information <em>could</em> be extracted from a representation. We care about whether it <em>is</em> by the model we&rsquo;re studying. Causal abstraction methods, which test counterfactual inputs to parts of the model that let uss modify specific information, can tell us this.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>I think NLP should employ more whacky analogies (see e.g. <a href=https://en.wikipedia.org/wiki/Leslie_Lamport>Leslie Lamport</a>&rsquo;s work on distributed systems). I am sorry in advance if this makes no sense!&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>I know it&rsquo;s not a perfect analogy so you can poke holes in it if you like. Or just assume every government worker is completely loyal so you can&rsquo;t just manipulate people to get what you want.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>I am a real scholar so I will try to cite some papers. But there&rsquo;s way too much probing literature to sift through. Start with ctrl-F &ldquo;probing&rdquo; on <a href=https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00349/96482/A-Primer-in-BERTology-What-We-Know-About-How-BERT>Rogers et al. (2021)</a>.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p><a href=https://arxiv.org/pdf/1906.04341.pdf>Clark et al. (2019)</a>&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p>From here on out, we are in the Wild West of mechanistic interpretability, where much interesting work is very recent and confined to blogposts that can be kind of hard to understand, rather than arXiv papers (which tbh are often still hard to understand). The earliest use of zero ablation is probably <a href=https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens>nostalgebraist (2020)</a>, who zero-ablated internal model layers to get a sort of early peak into what activations may mean in terms of the vocabulary. You see the method often used by LessWrong-ers. Also, note that zero ablation should be pretty useless on models trained with dropout (since that applies zero ablation to increase model robustness), as pointed out by <a href=https://www.neelnanda.io/mechanistic-interpretability/glossary>Neel Nanda</a>.&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6><p><strong>Path patching</strong> comes from <a href=https://arxiv.org/pdf/2211.00593.pdf>Wang et al. (2022)</a> which was the first work to find a circuit accomplishing a specific task in GPT-2 Small. The method is expounded upon in <a href=https://arxiv.org/pdf/2304.05969.pdf>Goldkowsky-Dill et al. (2023)</a> [which I am an author on]. <strong>Interchange interventions</strong> come from this line of work: <a href=https://arxiv.org/pdf/2301.04709.pdf>Geiger et al. (2023)</a>, <a href=https://proceedings.neurips.cc/paper/2021/file/4f5c422f4d49a5a807eda27434231040-Paper.pdf>Geiger et al. (2021)</a>. The basic idea between the two lines of work is the same, but I have yet to fully understand the latter series to be confident that the implementation is the same too.&#160;<a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:7><p>Resampling ablations are used in <a href=https://arxiv.org/pdf/2304.05969.pdf>Goldkowsky-Dill et al. (2023)</a>. A promising kind of work is automated circuit interpretability as implemented by <a href=https://arxiv.org/pdf/2304.14997.pdf>Conmy et al. (2023)</a>.&#160;<a href=#fnref:7 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/nlp/>NLP</a></li><li><a href=http://localhost:1313/tags/causality/>Causality</a></li></ul><nav class=paginav><a class=next href=http://localhost:1313/posts/2023-03-28-research/><span class=title>Next »</span><br><span>Me and Research</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Aryaman Arora</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>