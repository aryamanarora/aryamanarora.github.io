<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Papers | Aryaman Arora</title>
<meta name=keywords content><meta name=description content="You can also see my profiles on Google Scholar and Semantic Scholar.
Also check out acknowledgements.
2024 Zhengxuan Wu, Atticus Geiger, Aryaman Arora, Jing Huang, Zheng Wang, Noah D. Goodman, Christopher D. Manning, Christopher Potts. 2024. pyvene: A library for understanding and improving PyTorch models via interventions. arXiv:2403.07809. Aryaman Arora, Dan Jurafsky, Christopher Potts. 2024. CausalGym: Benchmarking causal interpretability methods on linguistic tasks. arXiv:2402.12560. Nay San, Georgios Paraskevopoulos, Aryaman Arora, Xiluo He, Prabhjot Kaur, Oliver Adams, Dan Jurafsky."><meta name=author content="Me"><link rel=canonical href=http://localhost:1313/papers/><link crossorigin=anonymous href=/assets/css/stylesheet.2c337fb86f9536060b454f4a8b7f1d6740cceb72dc167ed453d119184019fa6a.css integrity="sha256-LDN/uG+VNgYLRU9Ki38dZ0DM63LcFn7UU9EZGEAZ+mo=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/icon.png><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/icon.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/icon.png><link rel=apple-touch-icon href=http://localhost:1313/icon.png><link rel=mask-icon href=http://localhost:1313/icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/papers/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-W6HV8VE5SV"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-W6HV8VE5SV",{anonymize_ip:!1})}</script><meta property="og:title" content="Papers"><meta property="og:description" content="You can also see my profiles on Google Scholar and Semantic Scholar.
Also check out acknowledgements.
2024 Zhengxuan Wu, Atticus Geiger, Aryaman Arora, Jing Huang, Zheng Wang, Noah D. Goodman, Christopher D. Manning, Christopher Potts. 2024. pyvene: A library for understanding and improving PyTorch models via interventions. arXiv:2403.07809. Aryaman Arora, Dan Jurafsky, Christopher Potts. 2024. CausalGym: Benchmarking causal interpretability methods on linguistic tasks. arXiv:2402.12560. Nay San, Georgios Paraskevopoulos, Aryaman Arora, Xiluo He, Prabhjot Kaur, Oliver Adams, Dan Jurafsky."><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/papers/"><meta property="og:image" content="http://localhost:1313/icon.png"><meta property="article:section" content><meta property="og:site_name" content="Aryaman Arora"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/icon.png"><meta name=twitter:title content="Papers"><meta name=twitter:description content="You can also see my profiles on Google Scholar and Semantic Scholar.
Also check out acknowledgements.
2024 Zhengxuan Wu, Atticus Geiger, Aryaman Arora, Jing Huang, Zheng Wang, Noah D. Goodman, Christopher D. Manning, Christopher Potts. 2024. pyvene: A library for understanding and improving PyTorch models via interventions. arXiv:2403.07809. Aryaman Arora, Dan Jurafsky, Christopher Potts. 2024. CausalGym: Benchmarking causal interpretability methods on linguistic tasks. arXiv:2402.12560. Nay San, Georgios Paraskevopoulos, Aryaman Arora, Xiluo He, Prabhjot Kaur, Oliver Adams, Dan Jurafsky."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Papers","item":"http://localhost:1313/papers/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Papers","name":"Papers","description":"You can also see my profiles on Google Scholar and Semantic Scholar.\nAlso check out acknowledgements.\n2024 Zhengxuan Wu, Atticus Geiger, Aryaman Arora, Jing Huang, Zheng Wang, Noah D. Goodman, Christopher D. Manning, Christopher Potts. 2024. pyvene: A library for understanding and improving PyTorch models via interventions. arXiv:2403.07809. Aryaman Arora, Dan Jurafsky, Christopher Potts. 2024. CausalGym: Benchmarking causal interpretability methods on linguistic tasks. arXiv:2402.12560. Nay San, Georgios Paraskevopoulos, Aryaman Arora, Xiluo He, Prabhjot Kaur, Oliver Adams, Dan Jurafsky.","keywords":[],"articleBody":"You can also see my profiles on Google Scholar and Semantic Scholar.\nAlso check out acknowledgements.\n2024 Zhengxuan Wu, Atticus Geiger, Aryaman Arora, Jing Huang, Zheng Wang, Noah D. Goodman, Christopher D. Manning, Christopher Potts. 2024. pyvene: A library for understanding and improving PyTorch models via interventions. arXiv:2403.07809. Aryaman Arora, Dan Jurafsky, Christopher Potts. 2024. CausalGym: Benchmarking causal interpretability methods on linguistic tasks. arXiv:2402.12560. Nay San, Georgios Paraskevopoulos, Aryaman Arora, Xiluo He, Prabhjot Kaur, Oliver Adams, Dan Jurafsky. 2024. Predicting positive transfer for improved low-resource speech recognition using acoustic pseudo-tokens. In SIGTYP. Zhengxuan Wu, Atticus Geiger, Jing Huang, Aryaman Arora, Thomas Icard, Christopher Potts, and Noah D. Goodman. 2024. A reply to Makelov et al. (2023)’s “interpretability illusion” arguments. arXiv:2401.12631. Kabilan Prasanna, Aryaman Arora. 2024. IruMozhi: Automatically classifying diglossia in Tamil. In Findings of NAACL. 2023 Vedant Palit*, Rohan Pandey*, Aryaman Arora, Paul Pu Liang. 2023. Towards vision-language mechanistic interpretability: A causal tracing tool for BLIP. In 5th Workshop on Closing the Loop Between Vision and Language. Omer Goldman, Khuyagbaatar Batsuren, Salam Khalifa, Aryaman Arora, Garrett Nicolai, Reut Tsarfaty, Ekaterina Vylomova. 2023. SIGMORPHON–UniMorph 2023 Shared Task 0: Typologically diverse morphological inflection. In SIGMORPHON. Aryaman Arora, Adam Farris, Samopriya Basu, Suresh Kolichala. 2023. Jambu: A historical linguistic database for South Asian languages. In SIGMORPHON. Brett Reynolds, Aryaman Arora, Nathan Schneider. 2023. Unified syntactic annotation of English in the CGEL framework. In LAW. Aryaman Arora. 2023. Investigating induction heads in a small transformer language model. In MASC-SLL, Arlington, VA, USA. Nicholas Goldowsky-Dill, Chris MacLeod, Lucas Sato, Aryaman Arora. 2023. Localizing model behavior with path patching. arXiv:2304.05969. 2022 Ryan Cotterell, Richard Futrell, Kyle Mahowald, Clara Meister, Tiago Pimentel, Adina Williams, Aryaman Arora. 2022. Information theory in linguistics: Methods and applications. In COLING (tutorials). Brett Reynolds, Aryaman Arora, Nathan Schneider. 2022. CGELBank: CGEL as a framework for English syntax annotation. arXiv:2210.00394. Jordan Kodner, …, Aryaman Arora, …, Ekaterina Vylomova. 2022. SIGMORPHON–UniMorph 2022 Shared Task 0: Generalization and typologically diverse morphological inflection. In SIGMORPHON. Khuyagbaatar Batsuren, Gábor Bella, Aryaman Arora, …, Ryan Cotterell, Ekaterina Vylomova. 2022. The SIGMORPHON 2022 Shared Task on Morpheme Segmentation. In SIGMORPHON. Aryaman Arora. 2022. Universal Dependencies for Punjabi. In LREC. Aryaman Arora, Nitin Venkateswaran, Nathan Schneider. 2022. MASALA: Modelling and analysing the semantics of adpositions in linguistic annotation of Hindi. In LREC. Khuyagbaatar Batsuren*, Omer Goldman*, …, Aryaman Arora, …, Ryan Cotterell, Reut Tsarfaty, Ekaterina Vylomova. 2022. UniMorph 4.0: Universal Morphology. In LREC. Aryaman Arora, Nathan Schneider, Brett Reynolds. 2022. A CGEL-formalism English treebank. In MASC-SLL, Philadelphia, PA, USA. Aryaman Arora, Clara Meister, Ryan Cotterell. 2022. Estimating the entropy of linguistic distributions. In ACL. Aryaman Arora, Adam Farris, Samopriya Basu, Suresh Kolichala. 2022. Computational historical linguistics and language diversity in South Asia. In ACL. Adam Farris*, Aryaman Arora*. 2022. DIPI: Dependency parsing for Ashokan Prakrit historical dialectology. In Towards a comparative historical dialectology: evidence from morphology and syntax, DGfS, Tübingen, Germany. 2021 Adam Farris*, Aryaman Arora*. 2021. For the purpose of curry: A UD Treebank for Ashokan Prakrit. In UDW, SyntaxFest. Aryaman Arora, Adam Farris, Gopalakrishnan R, Samopriya Basu. 2021. Bhāṣācitra: Visualising the dialect geography of South Asia. In LChange. Aryaman Arora, Ahmed Etebari. 2021. Kholosi Dictionary. Aryaman Arora, Nitin Venkateswaran, Nathan Schneider. 2021. Adposition and case supersenses v1.0: Guidelines for Hindi–Urdu. arXiv:2103.01399. Aryaman Arora, Nitin Venkateswaran, Nathan Schneider. 2021. SNACS annotation of case markers and adpositions in Hindi. In SCiL. 2020 Michael Kranzlein, Emma Manning, Siyao Peng, Shira Wein, Aryaman Arora, Nathan Schneider. 2020. PASTRIE: A corpus of prepositions annotated with supsersense tags in Reddit International English. In LAW. Aryaman Arora, Nathan Schneider. 2020. SNACS annotation of case markers and adpositions in Hindi. In SIGTYP. Non-archival extended abstract. Aryaman Arora, Luke Gessler, Nathan Schneider. 2020. Supervised grapheme-to-phoneme conversion of orthographic schwas in Hindi and Punjabi. In ACL. 2019 Aryaman Arora, John R. McIntyre. 2019. Quasi-passive lower and upper extremity robotic exoskeleton for strengthening human locomotion. In Sustainable Innovation. ","wordCount":"649","inLanguage":"en","image":"http://localhost:1313/icon.png","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/papers/"},"publisher":{"@type":"Organization","name":"Aryaman Arora","logo":{"@type":"ImageObject","url":"http://localhost:1313/icon.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Aryaman Arora (Alt + H)">Aryaman Arora</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/about/ title=about><span>about</span></a></li><li><a href=http://localhost:1313/papers/ title=papers><span class=active>papers</span></a></li><li><a href=http://localhost:1313/posts/ title=blog><span>blog</span></a></li><li><a href=http://localhost:1313/search/ title=search><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a></div><h1 class="post-title entry-hint-parent">Papers</h1><div class=post-meta>4 min&nbsp;·&nbsp;649 words&nbsp;·&nbsp;Me</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><ul><li><a href=#2024>2024</a></li><li><a href=#2023>2023</a></li><li><a href=#2022>2022</a></li><li><a href=#2021>2021</a></li><li><a href=#2020>2020</a></li><li><a href=#2019>2019</a></li></ul></li></ul></nav></div></details></div><div class=post-content><p>You can also see my profiles on <a href="https://scholar.google.com/citations?user=0-4GKw8AAAAJ&amp;hl=en">Google Scholar</a> and <a href=https://www.semanticscholar.org/author/Aryaman-Arora/1575802390>Semantic Scholar</a>.</p><p>Also check out <a href=/acks>acknowledgements</a>.</p><h3 id=2024>2024<a hidden class=anchor aria-hidden=true href=#2024>#</a></h3><ol><li>Zhengxuan Wu, Atticus Geiger, <strong>Aryaman Arora</strong>, Jing Huang, Zheng Wang, Noah D. Goodman, Christopher D. Manning, Christopher Potts. 2024. <a href=https://arxiv.org/abs/2403.07809>pyvene: A library for understanding and improving PyTorch models via interventions</a>. <em>arXiv:2403.07809</em>. <span class=resource><a href=https://github.com/stanfordnlp/pyvene><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span> <span class=resource><a href=https://twitter.com/ZhengxuanZenWu/status/1767963562960630113><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a></span></li><li><strong>Aryaman Arora</strong>, Dan Jurafsky, Christopher Potts. 2024. <a href=https://arxiv.org/abs/2402.12560>CausalGym: Benchmarking causal interpretability methods on linguistic tasks</a>. <em>arXiv:2402.12560</em>. <span class=resource><a href=https://github.com/aryamanarora/causalgym><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span> <span class=resource><a href="https://x.com/aryaman2020/status/1762215502926237779?s=20"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a></span></li><li>Nay San, Georgios Paraskevopoulos, <strong>Aryaman Arora</strong>, Xiluo He, Prabhjot Kaur, Oliver Adams, Dan Jurafsky. 2024. <a href=https://arxiv.org/abs/2402.02302>Predicting positive transfer for improved low-resource speech recognition using acoustic pseudo-tokens</a>. In <em>SIGTYP</em>. <span class=resource><a href=https://anonymous.4open.science/r/2FF2/README.md><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span></li><li>Zhengxuan Wu, Atticus Geiger, Jing Huang, <strong>Aryaman Arora</strong>, Thomas Icard, Christopher Potts, and Noah D. Goodman. 2024. <a href=https://arxiv.org/abs/2401.12631>A reply to Makelov et al. (2023)’s “interpretability illusion” arguments</a>. <em>arXiv:2401.12631</em>. <span class=resource><a href=https://github.com/stanfordnlp/pyvene><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span> <span class=resource><a href="https://x.com/ZhengxuanZenWu/status/1750940728816247163?s=20"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a></span></li><li>Kabilan Prasanna, <strong>Aryaman Arora</strong>. 2024. <a href=https://arxiv.org/abs/2311.07804>IruMozhi: Automatically classifying diglossia in Tamil</a>. In <em>Findings of NAACL</em>. <span class=resource><a href=https://github.com/kebathan/diglossia><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span></li></ol><h3 id=2023>2023<a hidden class=anchor aria-hidden=true href=#2023>#</a></h3><ol start=6><li>Vedant Palit*, Rohan Pandey*, <strong>Aryaman Arora</strong>, Paul Pu Liang. 2023. <a href=https://arxiv.org/abs/2308.14179>Towards vision-language mechanistic interpretability: A causal tracing tool for BLIP</a>. In <em>5th Workshop on Closing the Loop
Between Vision and Language</em>. <span class=resource><a href=https://github.com/vedantpalit/Towards-Vision-Language-Mechanistic-Interpretability><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span></li><li>Omer Goldman, Khuyagbaatar Batsuren, Salam Khalifa, <strong>Aryaman Arora</strong>, Garrett Nicolai, Reut Tsarfaty, Ekaterina Vylomova. 2023. <a href=https://aclanthology.org/2023.sigmorphon-1.13/>SIGMORPHON–UniMorph 2023 Shared Task 0: Typologically diverse morphological inflection</a>. In <em>SIGMORPHON</em>. <span class=resource><a href=https://github.com/sigmorphon/2023InflectionST><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span></li><li><strong>Aryaman Arora</strong>, Adam Farris, Samopriya Basu, Suresh Kolichala. 2023. <a href=https://aclanthology.org/2023.sigmorphon-1.8/>Jambu: A historical linguistic database for South Asian languages</a>. In <em>SIGMORPHON</em>. <span class=resource><a href=https://github.com/moli-mandala/data><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span> <span class=resource><a href=https://neojambu.herokuapp.com/><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"/></svg></a></span></li><li>Brett Reynolds, <strong>Aryaman Arora</strong>, Nathan Schneider. 2023. <a href=https://aclanthology.org/2023.law-1.22/>Unified syntactic annotation of English in the CGEL framework</a>. In <em>LAW</em>. <span class=resource><a href=https://github.com/nert-nlp/cgel><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span></li><li><strong>Aryaman Arora</strong>. 2023. <a href="https://docs.google.com/presentation/d/1XyocheHUqMkjuoWVYNmdm7ep3nwjwIHpSwnM2Pwg0ZM/edit?usp=sharing">Investigating induction heads in a small transformer language model</a>. In <em>MASC-SLL</em>, Arlington, VA, USA. <span class=resource><a href=https://github.com/aryamanarora/induction><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span></li><li>Nicholas Goldowsky-Dill, Chris MacLeod, Lucas Sato, <strong>Aryaman Arora</strong>. 2023. <a href=https://arxiv.org/abs/2304.05969>Localizing model behavior with path patching</a>. <em>arXiv:2304.05969</em>. <span class=resource><a href=https://github.com/redwoodresearch/rust_circuit_public><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span> <span class=resource><a href="https://twitter.com/aryaman2020/status/1648544361599180804?s=20"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a></span></li></ol><h3 id=2022>2022<a hidden class=anchor aria-hidden=true href=#2022>#</a></h3><ol start=12><li>Ryan Cotterell, Richard Futrell, Kyle Mahowald, Clara Meister, Tiago Pimentel, Adina Williams, <strong>Aryaman Arora</strong>. 2022. <a href=https://rycolab.io/classes/info-theory-tutorial/>Information theory in linguistics: Methods and applications</a>. In <em>COLING (tutorials)</em>. <span class=resource><a href="https://colab.research.google.com/drive/16ay4Em4Ctn4ETUH1f5ww1JgzSJVk4G23?usp=sharing"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"/></svg></a></span></li><li>Brett Reynolds, <strong>Aryaman Arora</strong>, Nathan Schneider. 2022. <a href=https://arxiv.org/abs/2210.00394>CGELBank: CGEL as a framework for English syntax annotation</a>. <em>arXiv:2210.00394</em>. <span class=resource><a href=https://github.com/nert-nlp/cgel><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span></li><li>Jordan Kodner, &mldr;, <strong>Aryaman Arora</strong>, &mldr;, Ekaterina Vylomova. 2022. <a href=https://aclanthology.org/2022.sigmorphon-1.19/>SIGMORPHON–UniMorph 2022 Shared Task 0: Generalization and typologically diverse morphological inflection</a>. In <em>SIGMORPHON</em>. <span class=resource><a href=https://github.com/sigmorphon/2022InflectionST><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span></li><li>Khuyagbaatar Batsuren, Gábor Bella, <strong>Aryaman Arora</strong>, &mldr;, Ryan Cotterell, Ekaterina Vylomova. 2022. <a href=https://aclanthology.org/2022.sigmorphon-1.11/>The SIGMORPHON 2022 Shared Task on Morpheme Segmentation</a>. In <em>SIGMORPHON</em>. <span class=resource><a href=https://github.com/sigmorphon/2022SegmentationST><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span></li><li><strong>Aryaman Arora</strong>. 2022. <a href=https://aclanthology.org/2022.lrec-1.613/>Universal Dependencies for Punjabi</a>. In <em>LREC</em>. <span class=resource><a href=https://github.com/UniversalDependencies/UD_Punjabi-PunTB><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span></li><li><strong>Aryaman Arora</strong>, Nitin Venkateswaran, Nathan Schneider. 2022. <a href=https://aclanthology.org/2022.lrec-1.612/>MASALA: Modelling and analysing the semantics of adpositions in linguistic annotation of Hindi</a>. In <em>LREC</em>. <span class=resource><a href=https://github.com/aryamanarora/carmls-hi><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span></li><li>Khuyagbaatar Batsuren*, Omer Goldman*, &mldr;, <strong>Aryaman Arora</strong>, &mldr;, Ryan Cotterell, Reut Tsarfaty, Ekaterina Vylomova. 2022. <a href=https://aclanthology.org/2022.lrec-1.89/>UniMorph 4.0: Universal Morphology</a>. In <em>LREC</em>. <span class=resource><a href=https://github.com/unimorph><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span></li><li><strong>Aryaman Arora</strong>, Nathan Schneider, Brett Reynolds. 2022. <a href="https://docs.google.com/presentation/d/1muLMZyNLspXElkWaOLfGQve64SxbapXkXJpWpgNmFWw/edit?usp=sharing">A CGEL-formalism English treebank</a>. In <em>MASC-SLL</em>, Philadelphia, PA, USA. <span class=resource><a href=https://github.com/nert-nlp/cgel><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span></li><li><strong>Aryaman Arora</strong>, Clara Meister, Ryan Cotterell. 2022. <a href=https://aclanthology.org/2022.acl-short.20/>Estimating the entropy of linguistic distributions</a>. In <em>ACL</em>. <span class=resource><a href=https://github.com/rycolab/entropy-estimation><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span> <span class=resource><a href=https://twitter.com/aryaman2020/status/1522996992300904449><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a></span></li><li><strong>Aryaman Arora</strong>, Adam Farris, Samopriya Basu, Suresh Kolichala. 2022. <a href=https://aclanthology.org/2022.acl-long.99/>Computational historical linguistics and language diversity in South Asia</a>. In <em>ACL</em>. <span class=resource><a href=https://twitter.com/aryaman2020/status/1528935903720353792><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a></span></li><li>Adam Farris*, <strong>Aryaman Arora</strong>*. 2022. <a href="https://docs.google.com/presentation/d/1VbVqK67wfUVuT6ESnC2QAccN1cr-o0aaz3TDQ7UjaP0/edit?usp=sharing">DIPI: Dependency parsing for Ashokan Prakrit historical dialectology</a>. In <em>Towards a comparative historical dialectology: evidence from morphology and syntax, DGfS</em>, Tübingen, Germany. <span class=resource><a href=https://github.com/UniversalDependencies/UD_Prakrit-DIPI><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span> <span class=resource><a href=https://twitter.com/aryaman2020/status/1496763811583328259><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a></span></li></ol><h3 id=2021>2021<a hidden class=anchor aria-hidden=true href=#2021>#</a></h3><ol start=23><li>Adam Farris*, <strong>Aryaman Arora</strong>*. 2021. <a href=https://aclanthology.org/2021.udw-1.4/>For the purpose of curry: A UD Treebank for Ashokan Prakrit</a>. In <em>UDW, SyntaxFest</em>. <span class=resource><a href=https://github.com/UniversalDependencies/UD_Prakrit-DIPI><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span> <span class=resource><a href="https://docs.google.com/presentation/d/1j2DtdvlVlYaTc3b-V-RFYDVaydaZ-URkJ_N_Iy5KT4w/edit?usp=sharing"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"/></svg></a></span> <span class=resource><a href=https://twitter.com/aryaman2020/status/1506016257589403651><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a></span></li><li><strong>Aryaman Arora</strong>, Adam Farris, Gopalakrishnan R, Samopriya Basu. 2021. <a href=https://aclanthology.org/2021.lchange-1.7/>Bhāṣācitra: Visualising the dialect geography of South Asia</a>. In <em>LChange</em>. <span class=resource><a href=https://github.com/aryamanarora/bhasacitra><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span> <span class=resource><a href="https://docs.google.com/presentation/d/1PTw4zDP4XweJlGwOMqfB8tc7nnb30XFodJP25_jIqOU/edit?usp=sharing"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"/></svg></a></span> <span class=resource><a href="https://x.com/aryaman2020/status/1398301846935121920?s=20"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a></span></li><li><strong>Aryaman Arora</strong>, Ahmed Etebari. 2021. <em><a href=https://zenodo.org/record/7901554>Kholosi Dictionary</a></em>. <span class=resource><a href=https://github.com/aryamanarora/kholosi><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span> <span class=resource><a href="https://twitter.com/aryaman2020/status/1381399677610905605?s=20"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a></span></li><li><strong>Aryaman Arora</strong>, Nitin Venkateswaran, Nathan Schneider. 2021. <a href=http://arxiv.org/abs/2103.01399>Adposition and case supersenses v1.0: Guidelines for Hindi–Urdu</a>. <em>arXiv:2103.01399</em>. <span class=resource><a href=https://github.com/aryamanarora/carmls-hi><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span></li><li><strong>Aryaman Arora</strong>, Nitin Venkateswaran, Nathan Schneider. 2021. <a href=https://scholarworks.umass.edu/scil/vol4/iss1/57/>SNACS annotation of case markers and adpositions in Hindi</a>. In <em>SCiL</em>. <span class=resource><a href=https://github.com/aryamanarora/carmls-hi><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span></li></ol><h3 id=2020>2020<a hidden class=anchor aria-hidden=true href=#2020>#</a></h3><ol start=28><li>Michael Kranzlein, Emma Manning, Siyao Peng, Shira Wein, <strong>Aryaman Arora</strong>, Nathan Schneider. 2020. <a href=https://www.aclweb.org/anthology/2020.law-1.10/>PASTRIE: A corpus of prepositions annotated with supsersense tags in Reddit International English</a>. In <em>LAW</em>. <span class=resource><a href=https://github.com/mkranzlein/reddit-supersenses><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span></li><li><strong>Aryaman Arora</strong>, Nathan Schneider. 2020. <a href=https://sigtyp.github.io/workshops/2020/papers/8.pdf>SNACS annotation of case markers and adpositions in Hindi</a>. In <em>SIGTYP</em>. Non-archival extended abstract. <span class=resource><a href=https://github.com/aryamanarora/carmls-hi><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span> <span class=resource><a href="https://twitter.com/aryaman2020/status/1329258701874728962?s=20"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a></span></li><li><strong>Aryaman Arora</strong>, Luke Gessler, Nathan Schneider. 2020. <a href=https://www.aclweb.org/anthology/2020.acl-main.696>Supervised grapheme-to-phoneme conversion of orthographic schwas in Hindi and Punjabi</a>. In <em>ACL</em>. <span class=resource><a href=https://github.com/aryamanarora/schwa-deletion><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></span> <span class=resource><a href=https://aryamanarora.github.io/schwa-deletion/presentation/><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"/><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"/></svg></a></span></li></ol><h3 id=2019>2019<a hidden class=anchor aria-hidden=true href=#2019>#</a></h3><ol start=31><li><strong>Aryaman Arora</strong>, John R. McIntyre. 2019. <a href=https://link.springer.com/chapter/10.1007/978-3-030-30421-8_1>Quasi-passive lower and upper extremity robotic exoskeleton for strengthening human locomotion</a>. In <em>Sustainable Innovation</em>.</li></ol></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Aryaman Arora</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>