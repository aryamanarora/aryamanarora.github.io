---
title: About
---

I am a first-year Ph.D. student at [**Stanford NLP**](https://nlp.stanford.edu/) advised by [Dan Jurafsky](http://web.stanford.edu/~jurafsky/) and [Christopher Potts](https://web.stanford.edu/~cgpotts/). My research is focused on **interpretability**.

I want to understand how neural networks (like language models) work. I believe that this is a tractable goal that can be accomplished in my lifetime. Some things I've been thinking about recently:
- How can we ensure that explanations of model behaviour are actually faithful? New methods grounded in causal inferences are promising, but we still need more theory, benchmarks, metrics, etc.
- In a self-supervised learning world, can linguistics still be useful in guiding how we do interpretability on language models?
- Can interpretability provide actionable findings that help us make better models?

Machine learning is still a kind of alchemy. We should turn it into a science. To that end, I am inspired by work in NLP, causal inference, information theory, and psycholinguistics.

Oh, and besides doing research, I enjoy eating spicy food, (attempting to) play basketball and climb, and listening to rap. And if you handed me a violin, I would probably be able to make some sounds that are not too unpleasant.

If you want to chat about research or life, feel free to send me an email (aryamana [at] stanford [dot] edu)!

## Brief history

I was born in New Delhi, India, raised in Savannah, Georgia (the U.S. state), and I think of home as Washington, D.C.---where I spent part of high school and my undergrad. Still, I've wanted to move to the Bay Area for a long time, and I'm glad I made it here!

Before coming to Stanford to start my Ph.D. in 2023, I completed my B.S. in Computer Science and Linguistics at [Georgetown University](https://www.georgetown.edu/). There, I was mentored by [Nathan Schneider](https://people.cs.georgetown.edu/nschneid/) as a member of his research group [NERT](http://nert.georgetown.edu/). In those days, I primarily worked on computational linguistics and did a lot of linguistic annotation for Indian languages. Regardless of what I currently work on, my research *style* is probably largely copied from Nathan's.

Since 2021, I have also been closely working with [Ryan Cotterell](https://rycolab.io/authors/ryan/) at ETH ZÃ¼rich on information theory, and I visited Switzerland in Summer 2021 and 2023. From working with Ryan, I learned to be a little less scared of doing math.

In 2022, I spent the summer at [Apple](https://www.apple.com/) in Seattle with [Robert Daland](https://www.linkedin.com/in/robert-daland-176362111) working on evaluating robustness on a ton of languages for Siri, and winter at [Redwood Research](https://www.redwoodresearch.org/) in Berkeley working on mechanistic interpretability.

My research interests pivoted significantly in late 2022 towards interpretability, but I still have a love for language(s).